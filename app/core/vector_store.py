from collections import defaultdict
from pathlib import Path
from typing import Dict, Iterable, List, Set, Tuple
from uuid import uuid4

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

from app.core.config import CHROMA_DIR, EMBEDDING_DIR
from app.core.logging_config import get_logger

logger = get_logger(__name__)

# ‚îÄ‚îÄ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
MAX_FILES_PER_USER = 10
embedder = HuggingFaceEmbeddings(
    model_name="intfloat/multilingual-e5-base",
    cache_folder=str(EMBEDDING_DIR),
)
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)


# ‚îÄ‚îÄ‚îÄ –ø—É–±–ª–∏—á–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –±–∞–∑—ã (–¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –∏–∑ ai_reply –∏ –¥—Ä.) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def load_vector_db(persist_dir: Path | str = CHROMA_DIR) -> Chroma:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç Chroma-–±–∞–∑—É: –µ—Å–ª–∏ –∫–∞—Ç–∞–ª–æ–≥ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ—Ç,
    –∏–Ω–∞—á–µ —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π.
    """
    p_dir = Path(persist_dir)
    if p_dir.exists():
        db = Chroma(persist_directory=str(p_dir), embedding_function=embedder)
        logger.info(
            "Chroma –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (%s), –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: %d", p_dir, db._collection.count()
        )
        return db

    logger.info("Chroma –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî —Å–æ–∑–¥–∞—é –Ω–æ–≤—É—é (%s)", p_dir)
    return Chroma(embedding_function=embedder, persist_directory=str(p_dir))


# ‚îÄ‚îÄ‚îÄ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —É—Ç–∏–ª–∏—Ç–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _user_file_set(db: Chroma, user_id: int) -> Set[str]:
    """–û—Ç–¥–∞—ë—Ç –≤—Å–µ file_id, —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    try:
        res = db.get(where={"user_id": user_id}, include=["metadatas"])
        return {meta["file_id"] for meta in res["metadatas"]}
    except Exception:
        return set()


# ‚îÄ‚îÄ‚îÄ –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø–∏—Å–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def store_documents_async(
    file_text_data: Iterable[Tuple[str, str, str, int]],
    persist_dir: Path | str = CHROMA_DIR,
) -> Chroma | None:
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç Chroma:
      ‚Ä¢ –º–∞–∫—Å–∏–º—É–º 10 —Ñ–∞–π–ª–æ–≤ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è;
      ‚Ä¢ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π file_id ‚Üí –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø–∏—Å –≤–µ–∫—Ç–æ—Ä–æ–≤;
      ‚Ä¢ ¬´–ª–∏—à–Ω–∏–µ¬ª –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã (–∫–æ–≥–¥–∞ –ª–∏–º–∏—Ç –¥–æ—Å—Ç–∏–≥–Ω—É—Ç) –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è.
    """
    data = list(file_text_data)
    if not data:
        logger.warning("store_documents_async: –ø—É—Å—Ç–æ–π –≤—Ö–æ–¥")
        return None

    db = load_vector_db(persist_dir)

    # --- –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º -------------------------
    per_user: Dict[int, List[Tuple[str, str, str]]] = defaultdict(list)
    for file_id, file_name, text, user_id in file_text_data:
        per_user[user_id].append((file_id, file_name, text))

    # --- –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è --------------------------------------
    for user_id, files in per_user.items():
        existing = _user_file_set(db, user_id)

        for file_id, file_name, text in files:
            # –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å, –µ—Å–ª–∏ —Ç–∞–∫–æ–π file_id —É–∂–µ –±—ã–ª
            if file_id in existing:
                db._collection.delete(where={"file_id": file_id, "user_id": user_id})
                existing.remove(file_id)

            # –ø—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞
            if len(existing) >= MAX_FILES_PER_USER:
                logger.warning(
                    "‚è≠ user %s: –ª–∏–º–∏—Ç %d —Ñ–∞–π–ª–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞—é %s",
                    user_id,
                    MAX_FILES_PER_USER,
                    file_id,
                )
                continue

            # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤
            header = f"=== FILE: {file_name.lower()} ===\n"
            text_with_header = header + text
            chunks = splitter.split_text(text_with_header)

            ids = [f"{file_id}_{uuid4().hex[:8]}_{i}" for i in range(len(chunks))]
            metadatas = [
                {"file_id": file_id, "file_name": file_name, "user_id": user_id}
            ] * len(chunks)

            db._collection.add(
                ids=ids,
                documents=chunks,
                embeddings=embedder.embed_documents(chunks),
                metadatas=metadatas,
            )
            existing.add(file_id)
            logger.info(
                "‚úÖ user %s: —Å–æ—Ö—Ä–∞–Ω—ë–Ω %s (%d —á–∞–Ω–∫–æ–≤)", user_id, file_id, len(chunks)
            )

    db.persist()
    logger.info("üì¶ Chroma —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
    return db
