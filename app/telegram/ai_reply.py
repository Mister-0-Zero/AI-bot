import torch

from app.core.logging_config import get_logger
from app.core.vector_store import load_vector_db
from app.llm import get_model

logger = get_logger(__name__)
MAX_NEW_TOKENS = 120


def search_knowledge(query: str, k: int = 5) -> list[str]:
    db = load_vector_db()
    results = db.similarity_search(query, k=k)
    return [r.page_content for r in results]


def generate_reply(history: list[str]) -> str:
    latest_user_input = history[-1] if history else "..."

    logger.info(
        "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏, –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: %s", latest_user_input
    )

    prompt = (
        "–¢—ã AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –¥–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º "
        "–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–π–ª–æ–≤, –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å Google –î–∏—Å–∫–∞. "
        "–¢–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º–∏ –∏ —á–µ—Ç–∫–∏–º–∏.\n\n"
    )

    dialog = "\n".join(history)
    prompt += f"{dialog}\n–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:"

    # üîç –ü–æ–∏—Å–∫ –∑–Ω–∞–Ω–∏–π –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –≤–æ–ø—Ä–æ—Å—É
    context_chunks = search_knowledge(latest_user_input)
    if context_chunks:
        context = "\n\n".join(context_chunks)
        prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n" + prompt
        logger.info("–î–æ–±–∞–≤–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ë–î (%d —á–∞–Ω–∫–æ–≤)", len(context_chunks))
    else:
        logger.info("–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∏—Å—Ç–æ—Ä–∏—è")

    tokenizer, model = get_model()
    inputs = tokenizer(prompt, return_tensors="pt")

    with torch.no_grad():
        outputs = model.generate(
            input_ids=inputs["input_ids"],
            attention_mask=inputs["attention_mask"],
            max_new_tokens=MAX_NEW_TOKENS,
            pad_token_id=tokenizer.eos_token_id,
            do_sample=True,
            top_p=0.9,
            temperature=0.7,
        )

    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)

    if "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:" in decoded:
        answer = decoded.split("–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:")[-1].strip()
    else:
        answer = decoded.strip()

    logger.info(f"prompt: {prompt}")
    logger.info("–û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: %s", answer or "[–ø—É—Å—Ç–æ]")
    return answer or "ü§ñ –ü–æ–∫–∞ –Ω–µ –∑–Ω–∞—é, –∫–∞–∫ –æ—Ç–≤–µ—Ç–∏—Ç—å."
