import re
from typing import List

import tiktoken

from app.ai.groq_config import chat_completion
from app.core.logging_config import get_logger
from app.core.vector_store import load_vector_db

LLAMA_MODEL = "llama-3.3-70b-versatile"
MAX_CTX_TOKENS = 131_072  # –ø–æ–ª–Ω–æ–µ –æ–∫–Ω–æ –º–æ–¥–µ–ª–∏
MAX_OUTPUT_TOKENS = 32_768  # –ª–∏–º–∏—Ç Groq –Ω–∞ ¬´completion¬ª

try:
    _enc = tiktoken.encoding_for_model(LLAMA_MODEL)
except KeyError:  # fallback –¥–ª—è –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
    _enc = tiktoken.get_encoding("cl100k_base")


def _count_tokens(text: str) -> int:
    return len(_enc.encode(text))


def convert_md_to_html(text: str) -> str:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç **–∂–∏—Ä–Ω—ã–π** –∏ *–∫—É—Ä—Å–∏–≤* –∏–∑ Markdown –≤ HTML,
    —á—Ç–æ–±—ã Telegram –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ç–æ–±—Ä–∞–∑–∏–ª.
    """
    # —Å–Ω–∞—á–∞–ª–∞ –∂–∏—Ä–Ω—ã–π, –ø–æ—Ç–æ–º –∫—É—Ä—Å–∏–≤, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞–ª–∏—Å—å
    text = re.sub(r"\*\*(.+?)\*\*", r"<b>\1</b>", text)
    text = re.sub(r"\*(.+?)\*", r"<i>\1</i>", text)
    return text


logger = get_logger(__name__)


def _translate_ru_to_en(text: str) -> str:
    """
    –û–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º Groq ‚Äî –±–µ—Å–ø–ª–∞—Ç–Ω–æ –∏ 1-2 —Ç–æ–∫–µ–Ω–∞.
    """
    try:
        resp = chat_completion(
            [
                {"role": "system", "content": "Translate the text to English."},
                {"role": "user", "content": text},
            ],
            max_tokens=60,
            temperature=0.0,
        )
        return resp.strip()
    except Exception as e:
        logger.warning("Translation failed: %s", e)
        return ""


def search_knowledge(query: str, user_id: int, k: int = 8) -> List[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞–Ω–∫–∏ –∏–∑ –±–∞–∑—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    * –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ —É–ø–æ–º–∏–Ω–∞–µ—Ç ¬´—Ñ–∞–π–ª(—ã) –ø–æ ‚Ä¶¬ª ‚Äî —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏.
    * –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Ü–µ–ª–∏–∫–æ–º –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ, –∏—â–µ–º –µ—â—ë –∏ –∞–Ω–≥–ª–∏–π—Å–∫—É—é –≤–µ—Ä—Å–∏—é.
    """
    q = query.strip()
    words = q.split()
    if len(words) < 3:  # —Å–µ—Ä–≤–∏—Å-—Ñ—Ä–∞–∑—ã –Ω–µ —Ç—Ä–µ–±—É—é—Ç RAG
        return []

    # ‚îÄ‚îÄ –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    m = re.search(r"(?:—Ñ–∞–π–ª(?:—ã)? –ø–æ|files? (?:about|on))\s+([\w\-\.\s]+)", q, re.I)
    filename_hint = m.group(1).strip().lower() if m else None

    # ‚îÄ‚îÄ –≥–æ—Ç–æ–≤–∏–º —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ (ru + en) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    queries = [q]
    if not re.search(r"[A-Za-z]", q):  # —Ç–æ–ª—å–∫–æ –∫–∏—Ä–∏–ª–ª–∏—Ü–∞
        en = _translate_ru_to_en(q)
        if en:
            queries.append(en)

    db = load_vector_db()
    results = []

    # ‚îÄ‚îÄ –¥–µ–ª–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∫–∞–∂–¥–æ–º—É –∑–∞–ø—Ä–æ—Å—É ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    for q_ in queries:
        docs_scores = db.similarity_search_with_relevance_scores(
            q_,
            k=k,
            filter={"user_id": user_id},
        )
        results.extend(docs_scores)

    # ‚îÄ‚îÄ –æ–±—ä–µ–¥–∏–Ω—è–µ–º, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –±—ã–ª —Ö–∏–Ω—Ç) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    uniq: dict[str, float] = {}  # id -> best_score
    docs: dict[str, str] = {}  # id -> text

    for doc, score in results:
        fname = doc.metadata.get("file_name", "").lower()
        if filename_hint and filename_hint not in fname:
            continue  # –Ω–µ —Ç–æ—Ç —Ñ–∞–π–ª
        doc_id = doc.metadata["file_id"] + doc.page_content[:20]
        best = uniq.get(doc_id, 0)
        if score > best:
            uniq[doc_id] = score
            docs[doc_id] = doc.page_content

    # ‚îÄ‚îÄ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    min_score = 0.65 if len(words) == 3 else 0.55 if len(words) == 4 else 0.35

    # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
    return [docs[d] for d, s in uniq.items() if s >= min_score][:k]


MAX_MSGS = 6


def generate_reply(history: list[dict], user_id: int) -> str:
    latest_user_input = (
        next((m["text"] for m in reversed(history) if m["role"] == "user"), "...")
        .strip()
        .lower()
    )

    logger.info("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥: %s", latest_user_input)

    # ‚îÄ‚îÄ RAG-–∫–æ–Ω—Ç–µ–∫—Å—Ç ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    context_chunks = search_knowledge(latest_user_input, user_id)
    if context_chunks:
        context_block = "–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n" + "\n\n".join(context_chunks)
        system_prompt = (
            "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤ Google –î–∏—Å–∫–∞ "
            "–¥–ª—è —Ç–æ—á–Ω—ã—Ö, –∫—Ä–∞—Ç–∫–∏—Ö –∏ –ø–æ–Ω—è—Ç–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤. –ï—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞–≤–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã"
            "–¥–ª—è –≤—ã–¥–∞—á–∏ –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤. –ü–∏—à–∏ –ø–æ—à–∞–≥–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –∏–¥–µ–∏ –∏ —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.\n\n"
            + context_block
        )
    else:
        system_prompt = "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞."

    # ‚îÄ‚îÄ messages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    messages = [{"role": "system", "content": system_prompt}]
    for msg in history[-MAX_MSGS:]:
        messages.append({"role": msg["role"], "content": msg["text"].strip()})

    logger.info("–°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è Groq: %s", messages)

    # ‚îÄ‚îÄ –≤—ã–∑–æ–≤ Groq ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    RESERVED_OUT = 1024  # —Ö–æ—Ç–∏–º ‚â§1024 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –æ—Ç–≤–µ—Ç
    MAX_PROMPT = MAX_CTX_TOKENS - RESERVED_OUT

    def _messages_tokens(msgs: list[dict]) -> int:
        return sum(_count_tokens(m["content"]) + 4 for m in msgs) + 2

    # ‚Äî –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —É—Å–∞–¥–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ ‚Äî
    while True:
        prompt_tokens = _messages_tokens(messages)
        if prompt_tokens <= MAX_PROMPT:
            break

        # 1) —É–±–∏—Ä–∞–µ–º —Å–∞–º–æ–µ —Å—Ç–∞—Ä–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
        if len(messages) > 2:
            messages.pop(1)  # messages[0] ‚Äî system
            continue

        # 2) —Ä–µ–∂–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if "–ö–æ–Ω—Ç–µ–∫—Å—Ç:" in messages[0]["content"]:
            parts = messages[0]["content"].split("\n\n")
            if len(parts) > 2:  # ¬´–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n¬ª + ‚â•1 —á–∞–Ω–∫–∞
                parts.pop()
                messages[0]["content"] = "\n\n".join(parts)
                continue

        # 3) –∫—Ä–∞–π: –≥—Ä—É–±–æ –æ–±—Ä–µ–∑–∞–µ–º —Å—Ç—Ä–æ–∫—É
        messages[0]["content"] = messages[0]["content"][:8000] + "‚Ä¶"
        break

    # —Å–≤–æ–±–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏ –ª–∏–º–∏—Ç –≤—ã–≤–æ–¥–∞
    free_tokens = MAX_CTX_TOKENS - _messages_tokens(messages)
    max_tokens = min(RESERVED_OUT, free_tokens - 1, MAX_OUTPUT_TOKENS)

    logger.info(
        "prompt %d —Ç–æ–∫–µ–Ω–æ–≤, —Å–≤–æ–±–æ–¥–Ω–æ %d, –∑–∞–ø—Ä–∞—à–∏–≤–∞—é %d",
        MAX_CTX_TOKENS - free_tokens,
        free_tokens,
        max_tokens,
    )

    try:
        answer = chat_completion(
            messages,
            max_tokens=max_tokens,
            temperature=0.7,
            top_p=0.9,
            frequency_penalty=0.25,  # –º—è–≥–∫–æ –ø–æ–¥–∞–≤–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—ã
        )
    except Exception as e:
        logger.exception("Groq error: %s", e)
        return "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."

    answer = convert_md_to_html(answer.strip())
    logger.info("–û—Ç–≤–µ—Ç –æ—Ç Groq: %s", answer)
    return answer or "ü§ñ –ü–æ–∫–∞ –Ω–µ –∑–Ω–∞—é, –∫–∞–∫ –æ—Ç–≤–µ—Ç–∏—Ç—å."
