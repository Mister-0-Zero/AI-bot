# AI-bot

* English version is provided below / Английская версия расположена ниже.
* Бота можно найти как / the bot can be found as: **AI_Google_Disk_helper_bot**
## Описание проекта

**AI-bot** – это интеллектуальный помощник (чат-бот), разработанный для корпоративного использования. Он позволяет пользователям в естественной форме получать ответы на вопросы, обрабатывая запросы с помощью большой языковой модели (LLM) и внутренних данных компании. Цель проекта – упростить доступ к знаниям, содержащимся в документах и файлах организации, посредством удобного чат-интерфейса. AI-bot интегрируется с популярными сервисами (например, Telegram для общения и Google Drive для хранения данных), чтобы обеспечить быстрый и понятный диалог между пользователем и ИИ-ассистентом.

## Ключевые функции и возможности

- Интеграция с LLM: Бот использует современную языковую модель для генерации контекстуально уместных и осмысленных ответов. Благодаря этому AI-bot понимает вопросы на естественном языке и поддерживает диалог, помня историю переписки.
- Поддержка различных форматов файлов: AI-bot умеет работать с документами в форматах PDF, DOCX (Microsoft Word), TXT (текстовые файлы), CSV и XLSX (таблицы Excel). Пользователь может отправить файл боту, после чего встроенные модули чтения извлекут из него текст или данные. Это позволяет боту отвечать на вопросы по содержимому документов – например, искать факты в PDF-документе или анализировать таблицу из Excel.
- Работа с Google Drive: Бот поддерживает OAuth-аутентификацию для подключения к Google Drive пользователя. После предоставления доступа AI-bot способен находить и загружать файлы прямо с Google Drive. Это особенно удобно для случаев, когда информация хранится в корпоративном Google-диске: бот может быстро просканировать документы на Диске и использовать их содержание при формировании ответа.
- Мультимодальность ввода: Помимо текста, AI-bot способен обрабатывать и другие типы контента. Пользователь может предоставить боту информацию не только сообщением, но и прикрепив файл (документ, таблицу и т.д.) – бот автоматически распознает поддерживаемый формат и обработает вложение. (В будущем планируется расширить мультимодальные возможности, включая поддержку изображений и аудиосообщений.)
- Удобный интерфейс: Взаимодействие с AI-bot происходит в привычном чат-формате (например, через интерфейс Telegram). Доступны базовые команды, такие как стартовый вызов /start, который приветствует пользователя специальным сообщением и изображением. Бот может предоставлять кнопки для удобной навигации или продолжения диалога (например, кнопка «Reply» для повторной отправки запроса). Благодаря хранению контекста беседы, AI-bot может отвечать с учётом предыдущих сообщений, что делает взаимодействие более естественным и непрерывным.
### Примеры использования
- Поиск информации в документах: Сотрудник может спросить у бота: «Какие ключевые выводы содержатся в отчёте за прошлый квартал?» – прикрепив PDF-файл отчёта. AI-bot извлечёт текст из PDF, найдёт в нём ключевые моменты и сформулирует краткий ответ с основными выводами.
- Справочник по политике компании: Новый сотрудник задаёт вопрос: «Каков порядок оформления отпуска?» Бот обращается к актуальному документу из Google Drive (например, «Политика компании по отпускам.docx»), находит соответствующий раздел и предоставляет пользователю выдержку с объяснением процедуры.
- Анализ таблиц и данных: Пользователь загружает CSV-файл с продажами или Excel-таблицу и спрашивает: «Какой был общий объём продаж в первом квартале?» AI-bot прочитает таблицу, при необходимости преобразует её в текстовое представление, после чего языковая модель проанализирует данные и выдаст ответ (например: «Общий объём продаж за Q1 составил 1,2 млн единиц»).
- Поддержка диалога: В ходе переписки пользователь может уточнять запрос. Например, сначала: «Найди информацию о проекте X в документации», затем: «Что говорится об этапе тестирования?» Бот сохранит контекст – документацию по проекту X – и ответит на второй вопрос, опираясь на найденные ранее сведения.
- Консультация и помощь: AI-bot можно использовать для быстрого получения справки. Например, запрос: «Что такое AI-bot и для чего он нужен?» – на что бот ответит кратким описанием проекта и его возможностей, фактически используя свои собственные описательные данные.

## Архитектура и ключевые компоненты

**AI-bot построен по модульному принципу, сочетая в себе несколько компонентов для обработки запросов и данных:**
- Интерфейс чат-бота: Основой взаимодействия служит Telegram-бот (реализованный с использованием библиотеки python-telegram-bot), который принимает сообщения от пользователей, файлы и команды. Этот слой отвечает за доставку пользовательских запросов во внутреннюю систему AI-bot и отправку готовых ответов обратно в чат.
- LLM-модель и обработка диалога: За генерацию ответов отвечает крупная языковая модель. Архитектура позволяет гибко менять модель: в текущей версии подключена облачная модель Llama 70B (через API-сервис Groq Cloud), ранее использовались и более лёгкие модели (например, TinyLlama). Компонент формирования ответа собирает подсказку (prompt) для модели, включая системные инструкции (роль ассистента) и последние сообщения из истории диалога для контекста. Затем запрос отправляется к LLM через API, и полученный ответ возвращается пользователю.
- Система работы с файлами: В директории app/services/reader реализованы специализированные модули-чтения для каждого типа файлов – PdfReader, DocxReader, TxtReader, CsvReader, ExcelReader. Когда пользователь отправляет файл, AI-bot определяет его MIME-тип и выбирает соответствующий ридер. Например, для PDF используется библиотека PyMuPDF для извлечения текста, для DOCX – библиотека python-docx, для CSV/Excel – библиотека pandas (с ограничением на количество обрабатываемых строк, чтобы избежать перегрузки). Извлечённый из файла текст автоматически сохраняется в базу знаний бота.
- Векторное хранилище знаний: Извлечённые из документов тексты индексируются с помощью модели эмбеддингов. AI-bot использует библиотеку SentenceTransformers для преобразования фрагментов текста в векторные представления. Эти векторы сохраняются в локальной базе ChromaDB, что позволяет осуществлять последующий поиск схожих по смыслу фрагментов. При новом вопросе пользователя компонент поиска знаний (Retrieval) сравнивает запрос с векторами в базе и находит релевантные кусочки текста из ранее загруженных документов. Найденные фрагменты (RAG-контекст) добавляются к prompt языковой модели, благодаря чему ответы бота могут опираться на факты из корпоративных источников, а не только на параметры самой LLM.
- Интеграция с Google API: Модуль app/services/google_drive.py отвечает за связь с Google Drive. Он управляет OAuth2-аутентификацией (используя CLIENT_ID и CLIENT_SECRET приложения) и получением токенов доступа. После авторизации пользователя бот может запрашивать список файлов или скачивать файлы с Google Drive для последующего анализа. Данные OAuth хранятся безопасно (например, в базе данных) с привязкой к аккаунту пользователя Telegram, чтобы обеспечить приватность и доступ только к своим файлам. Помимо возможности просматривать и скачивать файлы с диска, бот поддерживает интерактивный выбор пользователем конкретных файлов и папок, что даёт более гибкий контроль над передаваемыми данными.
- Хранение и управление состоянием: Для сохранения данных и настройки используются несколько подходов. Переписка с пользователем (история сообщений) может храниться в памяти во время сессии бота, а некоторые служебные данные – в Redis (например, кэш ответов или временные данные) для быстрого доступа. Кроме того, задействована реляционная база данных (подключение настраивается через DATABASE_URL): в ней могут сохраняться долговременные сведения – например, учетные данные для Google Drive, индексы документов или другие настройки, необходимые между запусками бота.
- Прочие компоненты: Проект содержит конфигурационный модуль (app/core/config.py), управляющий переменными окружения и основными параметрами (токен бота, ключи API, пути к локальным ресурсам и пр.). Также реализованы утилиты для запуска (скрипт run.bat для быстрого старта на Windows) и файлы требований (requirements.txt описывает используемые библиотеки: помимо вышеназванных, там присутствуют torch и accelerate для работы с моделью, huggingface_hub для загрузки моделей, langchain и др.).
- В совокупности архитектура AI-bot представляет собой конвейер: чат-интерфейс → обработка запроса (включая поиск по знаниям) → LLM-модель → генерация ответа, обогащённый данными из корпоративных источников. Такая система облегчает сотрудникам доступ к необходимой информации, позволяя получать ответы на вопросы без прямого поиска по документам вручную.
Планы на будущее

### AI-bot активно развивается, и в дальнейших версиях планируется реализовать ряд улучшений и новых возможностей:

- Расширение набора команд: Добавить больше команд управления и помощи. Например, команды для вывода справки о боте (/help), список доступных документов или очистки контекста, настройки уровней детализации ответов и т.п. Это сделает взаимодействие с ботом более прозрачным и настраиваемым.
- Улучшение алгоритмов и модели: Планируется оптимизировать алгоритм поиска по знаниям (более точная выборка контекста, ранжирование результатов), а также совершенствовать саму генерацию ответов. Возможен переход на новые, более мощные языковые модели по мере их появления или дополнительное тонкое обучение (fine-tuning) модели под специфические данные компании для повышения релевантности ответов.
- Подключение нескольких источников данных: В перспективе бот сможет одновременно работать с несколькими хранилищами. Например, обеспечить доступ не только к личному Google Drive пользователя, но и к общим командным дискам или другим облачным сервисам (OneDrive, Dropbox) при соответствующей интеграции. Это даст возможность объединённого поиска информации по разным ресурсам.
- Поддержка больших файлов и новых форматов: Сейчас существуют ограничения на размер обрабатываемых файлов (для обеспечения скорости и эффективности работы). В будущем планируется оптимизировать работу с объёмными документами (разбиение на блоки, асинхронная обработка) и снять ограничения на их размер. Кроме того, добавится поддержка новых типов файлов – например, презентаций PowerPoint (PPTX), форматов Markdown, а также расширенная обработка сканированных PDF (с применением OCR).
- Расширение мультимодальных возможностей: В дальнейшем AI-bot может научиться работать с изображениями (распознавать текст на изображениях, описывать содержимое картинок) и аудио (расшифровывать голосовые сообщения пользователей и даже отвечать голосом с помощью технологий синтеза речи). Это позволит пользователям общаться с ботом на удобном для них языке и форме, будь то текст, голос или визуальная информация.

* Развивая эти направления, AI-bot станет ещё более мощным и универсальным инструментом, способным служить личным ассистентом для сотрудников и эффективно поддерживать широкий спектр задач – от поиска данных до аналитики и консультаций.

# AI-bot (English)
* Project Description

**AI-bot** is an intelligent assistant (chatbot) designed for corporate use, enabling users to get answers to their questions in natural language. It leverages a large language model (LLM) alongside the company’s internal data and documents to provide informative responses. The project’s goal is to simplify access to information stored in various files and knowledge bases through a convenient chat interface. AI-bot integrates with popular services (such as Telegram for the chat interface and Google Drive for data storage) to facilitate a seamless dialogue between the user and the AI assistant, allowing users to retrieve information quickly and effortlessly.

## Key Features and Capabilities

- LLM-Powered Conversation: The bot utilizes a state-of-the-art language model to generate contextually relevant and meaningful answers. This integration allows AI-bot to understand natural language queries and engage in dialogue while remembering the conversation history for context. Users can ask complex or follow-up questions, and the LLM will produce human-like responses.
- Multiple File Format Support: AI-bot can process documents in various formats, including PDF, DOCX (Word documents), TXT (plain text), as well as CSV and XLSX (Excel spreadsheets). Users can upload a file to the bot, after which built-in reader modules will extract text or data from the file. This capability means the bot can answer questions based on the content of documents – for example, scanning a PDF for relevant information or interpreting data from a spreadsheet to inform its response.
- Google Drive Integration: The bot supports OAuth authentication to connect with the user’s Google Drive. With the user’s permission, AI-bot can search and fetch files directly from Google Drive for analysis. This is especially useful if key information is stored in the company’s Google Drive – the bot can quickly scan those documents and incorporate their content when formulating an answer.
- Multimodal Input: In addition to plain text input, AI-bot can handle other types of content. A user can provide information by attaching a file (document, spreadsheet, etc.) to the chat, and the bot will automatically recognize supported formats and process the attachment. (Expansion of multimodal capabilities is planned – for instance, future versions may support image and audio inputs.) This flexibility allows users to supply context or data in the form that’s most convenient for them, beyond just typing messages.
- User-Friendly Interface: Interaction with AI-bot takes place in a familiar chat format (e.g., via a Telegram bot). Basic commands are available, such as the /start command which triggers a welcome message (with a greeting image and introduction). The bot can also present interactive buttons to improve user experience – for example, a "Reply" button to easily resend or refine a query. Because the bot maintains conversational context, it can provide answers that take into account previous messages, making the dialogue feel more natural and continuous.
### Usage Examples
- Information Retrieval from Documents: An employee might ask the bot, “What are the key findings in last quarter’s report?” while attaching the report PDF. AI-bot will extract the text from the PDF, identify the main points, and respond with a concise summary of the report’s key findings.
- Company Policy FAQ: A new hire could query, “What is the procedure for applying for leave?” The bot will access the relevant Google Drive file (e.g., "Company Leave Policy.docx"), find the section about leave application, and reply with an explanation of the procedure, quoting or summarizing the policy as needed.
- Analyzing Tables and Data: A user uploads a CSV file of sales data or an Excel spreadsheet and asks, “What were the total sales in Q1?” AI-bot reads the file, converts it to a text or data frame internally, and then uses the LLM to analyze it. The bot can then answer with the figure (for example: “Total sales in Q1 were 1.2 million units.”). In this way, the bot helps interpret structured data by combining file parsing with language understanding.
- Contextual Dialogue: During a conversation, the user can ask follow-up questions without re-uploading files or restating context. For instance, the user first requests, “Find information about project X in the documentation,” and then asks, “What does it say about the testing phase?” AI-bot will have stored the context — documentation about project X — and will use it to answer the follow-up question about the testing phase accurately, based on the previously retrieved content.
- General Assistance and Q&A: AI-bot can also be used for general inquiries or quick advice. For example, a user might ask, “What is AI-bot and what is it used for?” The bot will then provide a brief description of the project and its capabilities (essentially summarizing itself), demonstrating how it can articulate information drawn from its own documentation.
## Architecture and Key Components
**AI-bot’s architecture is modular, combining several components to handle user queries and data processing:**
- Chat Interface Layer: The front-end of the system is a Telegram bot (built with the python-telegram-bot library) that manages user interactions. It receives user messages, commands, and file uploads, and delivers the AI’s responses back to the user. This layer handles connectivity to the chat service, command parsing, and ensures that each user’s messages are passed to the AI-bot core for processing.
- LLM Integration & Dialogue Management: AI-bot’s brain is a large language model. The architecture is designed to be model-agnostic, so the underlying LLM can be updated or changed easily. In the current version, a powerful Llama 70B model (accessible via the Groq Cloud API) is used to generate responses, whereas earlier iterations used smaller models like TinyLlama. The response generation component constructs a prompt for the model, which includes a system instruction (defining the assistant’s role and style) and the most recent dialogue history for context. It then calls the LLM through its API and obtains a completion, which is returned as the bot’s answer. This allows the bot to produce detailed, context-aware answers even as conversations evolve.
- File Processing System: Within app/services/reader, the project implements dedicated reader modules for each supported file type – e.g., PdfReader, DocxReader, TxtReader, CsvReader, ExcelReader. When a user sends a file, AI-bot determines its MIME type and invokes the appropriate reader. For instance, PDF files are handled via PyMuPDF to extract text, Word documents via python-docx, and CSV/Excel files via pandas (with row limits in place to prevent excessive data processing). The extracted text or data from the file is then automatically incorporated into the bot’s knowledge base.
- Vector Knowledge Base (Embedding + Search): Text content extracted from user-provided documents is indexed for quick retrieval. AI-bot uses SentenceTransformers to convert chunks of text into vector embeddings (numerical representations of semantic content). These embeddings are stored in a local ChromaDB vector database, enabling semantic search. When the user asks a question, a knowledge retrieval step compares the query against the stored vectors to find relevant text snippets from previously uploaded documents. Any matching content (the retrieval-augmented context) is then added to the LLM’s prompt. This Retrieval-Augmented Generation approach allows the bot to ground its answers in factual information from the company’s documents, rather than relying solely on the LLM’s trained knowledge.
- Integration with Google API: Module app/services/google_drive.py responsible for communication with Google Drive. It manages OAuth2 authentication (using the application's CLIENT_ID and CLIENT_SECRET) and the receipt of access tokens. After user authorization, the bot can request a list of files or download files from Google Drive for further analysis. OAuth data is stored securely (for example, in a database) linked to the user's Telegram account to ensure privacy and access only to their files. In addition to the ability to view and download files from yandex. disk, the bot supports interactive user selection of specific files and folders, which gives more flexible control over the transmitted data.
- State Management and Persistence: AI-bot uses a combination of in-memory and persistent storage to manage state. Conversation history with the user is kept in memory while the bot is running, and some transient data or caching might utilize Redis (for instance, caching model responses or storing session-specific flags) for quick look-ups. Additionally, a relational database (configured via a DATABASE_URL) is used for persistent data such as user credentials (e.g., Google Drive OAuth tokens), document indexes or metadata, and other configuration needed between restarts. This ensures that user-specific settings and data (like authorized Drive access or stored knowledge embeddings) persist over time and do not require re-entry.
- Additional Components: The project includes a configuration module (app/core/config.py) which centralizes environment variables and settings (bot token, API keys, file paths, etc.). There's also a helper startup script (run.bat for Windows) and a requirements.txt that lists all dependencies. Key libraries include torch and accelerate (for running ML models efficiently), huggingface_hub (for loading models or datasets as needed), and others like langchain (potentially for orchestration, if used). Each part of the system is designed to work asynchronously and efficiently, enabling the bot to handle multiple user requests concurrently and maintain responsiveness.
- Overall, AI-bot’s architecture functions as a pipeline: Chat Interface → Query & Document Processing (with optional knowledge retrieval) → LLM → Response Generation. By augmenting the LLM with enterprise data, the bot becomes a powerful assistant that can deliver precise information and insights from the company’s own knowledge stores, all through a simple conversational experience.

## Future Plans

**The AI-bot project is under active development, and several enhancements and new features are planned for future releases:**
- Expanded Command Set: Introduction of more user commands for better control and help. For example, commands to display help information (such as /help), list currently uploaded or indexed documents, clear the conversation history or reset context, and adjust settings like the detail level of answers. These additions will make the bot more transparent to use and allow users to tailor its behavior to their needs.
- Algorithm and Model Improvements: Ongoing work will focus on optimizing the knowledge retrieval algorithms (for instance, improving the accuracy of relevant context selection and ranking of results) as well as refining the answer generation. The team may integrate newer, more powerful language models as they become available, or perform additional fine-tuning of the current model on company-specific data to increase the relevance and accuracy of responses. This continuous improvement ensures AI-bot stays at the cutting edge of AI assistance.
- Multiple Data Source Integration: In the future, the bot may be able to interface with multiple data repositories simultaneously. For example, beyond a personal Google Drive, it could be connected to shared team drives or even other cloud storage services like OneDrive or Dropbox, given proper integration. This would enable unified information retrieval across various platforms – the bot could pull relevant data from wherever it resides.
- Support for Larger Files and New Formats: Presently, there are practical limits on the size of files the bot can efficiently process (imposed to maintain speed and avoid memory issues). Future versions will aim to handle much larger documents by employing strategies such as intelligent chunking, streaming processing, or asynchronous handling of content. Additionally, support for more file formats is on the roadmap – for instance, PowerPoint presentations (PPTX), Markdown files, and improved handling of scanned PDFs via OCR. By broadening format support, AI-bot will cater to an even wider range of use cases and document types.
- Enhanced Multimodal Capabilities: The project envisions extending the bot’s abilities to true multimodal interactions. This could include image understanding (e.g., extracting text from images or providing descriptions of images) and audio processing (transcribing voice messages from users and potentially replying with synthesized voice). Such features would allow users to communicate with the bot in whichever mode is most convenient – be it typing, speaking, or sending a photo – making the assistant more accessible and versatile.
* By pursuing these enhancements, AI-bot is set to become an even more powerful and universal tool, capable of serving as a personal assistant for employees and supporting a broad spectrum of tasks – from data retrieval and analysis to interactive help and decision support. These future improvements will help ensure that AI-bot continues to deliver value and keep pace with the evolving needs of its users.